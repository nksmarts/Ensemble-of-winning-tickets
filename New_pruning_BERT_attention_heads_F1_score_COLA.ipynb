{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nksmarts/Ensemble-of-winning-tickets/blob/main/New_pruning_BERT_attention_heads_F1_score_COLA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXFy261B2mH8"
      },
      "source": [
        "# **Checking the GPU we are currently using**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zuLzuzeU2TP",
        "outputId": "98a93ea3-aa9f-4301-a2c5-8a2a681f4bf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun 19 07:22:34 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le1AgaSZ3CKx",
        "outputId": "bb270e0d-b74c-47d9-c3fa-962bdad47209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-abad6dd8-873f-3791-52b0-8e31950b1723)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s67iW0fk2yCJ"
      },
      "source": [
        "# **Installing transformers, datasets and numpy library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WDZRczuu-K42"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets numpy > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-bvEEkA3TJ4"
      },
      "source": [
        "# **Importing required libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IvzdnY2n0Ef6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from datasets import (\n",
        "    load_dataset,\n",
        "    load_metric,\n",
        "    DatasetDict,\n",
        "    Dataset,\n",
        ")\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    set_seed,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCoSNkdC3qXJ"
      },
      "source": [
        "# **Setting Constants**:\n",
        "We're going to use SEED, for shuffling our dataset, transformer models and everywhere we use something that is done randomly so we get the same result each time. CHECKPOINT is used to when we load the model and the tokenizer of the model, you can simply change the CHECKPOINT to a similiar model and run this whole notebook and it will work; for example you can change it to bert-base-uncased."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YNKyvWLc1OFQ"
      },
      "outputs": [],
      "source": [
        "SEED = 8000\n",
        "CHECKPOINT = \"bert-base-uncased\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByJ4W7SWwRHH"
      },
      "source": [
        "# **Loading COLA Dataset from glue Benchmark**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkVF2HNhwP2H",
        "outputId": "34502bed-7679-4cf6-dcbc-858000de75b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "cola_dataset = load_dataset(\"glue\", \"cola\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCDXoYD1xVIP"
      },
      "source": [
        "# **Creating a Smaller Version of COLA Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_jQrFRW1xZTV"
      },
      "outputs": [],
      "source": [
        "select_example = cola_dataset[\"train\"].select(range(1000))\n",
        "\n",
        "custom_cola = DatasetDict({\n",
        "    \"train\": cola_dataset[\"train\"].shuffle(seed=SEED).select(range(8000)).flatten_indices(),\n",
        "    \"validation\": cola_dataset[\"validation\"],\n",
        "    \"test\": cola_dataset[\"train\"].shuffle(seed=SEED).select(range(1000, 2000)).flatten_indices()\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "q104FHdTL_Lf",
        "outputId": "f8cdd8d0-4990-4a58-9764-13be6c697f54"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Create a Pandas DataFrame to store the class labels and their counts\n",
        "labels = [\"Acceptable\", \"unacceptable\"]\n",
        "train_counts = [len(custom_cola[\"train\"].filter(lambda example: example[\"label\"] == 1)),\n",
        "                len(custom_cola[\"train\"].filter(lambda example: example[\"label\"] == 0))]\n",
        "data = {\"Class Labels\": labels, \"Counts\": train_counts}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Plot the bar chart using matplotlib\n",
        "plt.bar(df[\"Class Labels\"], df[\"Counts\"])\n",
        "\n",
        "# Set the labels and title\n",
        "plt.xlabel(\"Class Labels\")\n",
        "plt.ylabel(\"Counts\")\n",
        "plt.title(\"Distribution of Class Labels in Custom cola Dataset\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpAJiqMfxm89"
      },
      "source": [
        "# **Defining Compute Metric**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8LgXeFs_44BA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mLAM4I4myXbR"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    f1 = f1_score(labels, predictions)\n",
        "    return {\"f1_score\": f1}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dynqpT3Kyk5u"
      },
      "source": [
        "# **Set Transformers Seed**\n",
        "If we don't set the seed, the first time we train a model, the transformers library is going to set a seed itself. more information about this: https://discuss.huggingface.co/t/multiple-training-will-give-exactly-the-same-result-except-for-the-first-time/8493?u=smmousavi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Utm0azy7zt42"
      },
      "outputs": [],
      "source": [
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sORd3f40j_v"
      },
      "source": [
        "# **Loading the Model and the Tokenizer and Tokenizing the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "37feb8efbec74945bfc80a51f26e3b29",
            "9328f0ed981a47d6bba51206ef937ef3",
            "a26dbf294145428fa9ade6d8820ab8ec",
            "fb920cdaac3c4edd8cd096c6cabdf999",
            "eb63c2c8ba344a8cac8bc02fe29a9675",
            "b5a21f30f43048dab34ead077bef8a36",
            "6cc07f578836409b85027b22c56aa8c4",
            "944151739a1a4541b132b5834bcbc8ad",
            "2000dd9c37894e37aacb3c5d37144d36",
            "80f66a1c13e64f70907dfc423f687732",
            "5ab541a7523d484db2b0cd44fd8a5b26"
          ]
        },
        "id": "TXugicg10r5v",
        "outputId": "e3cae2e6-5759-4e06-a5df-5136613f03f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1043 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37feb8efbec74945bfc80a51f26e3b29"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "num_labels = len(custom_cola[\"train\"].unique('label'))\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(CHECKPOINT, num_labels=num_labels)\n",
        "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence\"], truncation=True)\n",
        "\n",
        "tokenized_datasets = custom_cola.map(tokenize_function, batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgN8vSm51-SX"
      },
      "source": [
        "# **Initialize an empty ensemble set to store the winning tickets?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Z8U_fRcU2BUH"
      },
      "outputs": [],
      "source": [
        "ensemble_set = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQPq-cKJ7AR4",
        "outputId": "418c048d-d83d-46e0-8efd-ffa316c28b97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvuPAGkv5kSn"
      },
      "source": [
        "# **Set the training parameters:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pND5Co8q9d_R",
        "outputId": "97b05130-4ffb-4f8f-ca9d-d2267e816dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Set the training parameters:\n",
        "num_iterations = 5  # Number of training iterations\n",
        "learning_rate = 2e-5  # Learning rate for optimization\n",
        "batch_size = 16  # Batch size for training\n",
        "convergence_threshold = 0.001  # Threshold for convergence criteria\n",
        "\n",
        "# For each ensemble iteration:\n",
        "for iteration in range(num_iterations):\n",
        "\n",
        "    # Initialize a mask matrix for the attention heads with all values set to 1\n",
        "    mask_matrix = torch.ones(model.config.num_hidden_layers, model.config.num_attention_heads)\n",
        "\n",
        "    # Randomly initialize a sub-network (ticket) based on the BERT architecture\n",
        "    # Assuming you have a variable CHECKPOINT that contains the path to the checkpoint file\n",
        "    checkpoint_path = CHECKPOINT\n",
        "    ticket = BertForSequenceClassification.from_pretrained(checkpoint_path)\n",
        "\n",
        "    # Set the optimizer and loss function for the sub-network\n",
        "    optimizer = optim.Adam(ticket.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxJC_WC6FdrK"
      },
      "source": [
        "# **Setting Training Arguments and Creating a Trainer Object**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnQ-OWflG3iZ",
        "outputId": "a94a7d1b-dec7-46cf-ac6a-6ef9deb0d815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.31.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.5.40)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.31.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JbJmq-wFg2p",
        "outputId": "807ed959-8929-4cd0-abe1-ccef6dd802d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "saving_folder = \"custom_cola_bert\"\n",
        "training_args = TrainingArguments(\n",
        "    saving_folder,\n",
        "    load_best_model_at_end=True,\n",
        "    num_train_epochs=3,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    save_steps=100,\n",
        "    metric_for_best_model=\"f1_score\",\n",
        "    save_total_limit=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    ticket,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S6jFGMwDsyM",
        "outputId": "8ac3fd5a-ebae-4111-d16a-488a519d796e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "50vmrWz8kD9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8193a20b-4019-4915-f064-443cd3421aa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install wandb onnx -Uq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Soqg_FE6UFA9"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "MAydBcNQ1BOU",
        "outputId": "f6dfeb06-dd6e-4165-a187-6e621284e3e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnyalalani-smarts\u001b[0m (\u001b[33msmarts-raja-venu\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240619_072426-6psovu3h</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/smarts-raja-venu/uncategorized/runs/6psovu3h' target=\"_blank\">young-paper-46</a></strong> to <a href='https://wandb.ai/smarts-raja-venu/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/smarts-raja-venu/uncategorized' target=\"_blank\">https://wandb.ai/smarts-raja-venu/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/smarts-raja-venu/uncategorized/runs/6psovu3h' target=\"_blank\">https://wandb.ai/smarts-raja-venu/uncategorized/runs/6psovu3h</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/1500 03:38, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.479400</td>\n",
              "      <td>0.439961</td>\n",
              "      <td>0.874121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.273900</td>\n",
              "      <td>0.511481</td>\n",
              "      <td>0.878650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.167900</td>\n",
              "      <td>0.729722</td>\n",
              "      <td>0.880674</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='870' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 870/1500 01:53 < 01:22, 7.67 it/s, Epoch 1.74/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.487100</td>\n",
              "      <td>0.462198</td>\n",
              "      <td>0.871049</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import f1_score\n",
        "import wandb\n",
        "import os\n",
        "\n",
        "# Set your API key here\n",
        "wandb.login(key=\"5e5d87b667a13d2738d9d28e12a263699ee7e843\")\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(settings=wandb.Settings(start_method=\"fork\"))\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(-1)\n",
        "    f1 = f1_score(labels, predictions)\n",
        "    return {\"eval_f1_score\": f1}\n",
        "\n",
        "def ensemble_bert(num_iterations, learning_rate, batch_size, convergence_threshold):\n",
        "    ensemble_set = []\n",
        "    for iteration in range(num_iterations):\n",
        "        mask_matrix = torch.ones(model.config.num_hidden_layers, model.config.num_attention_heads)\n",
        "        ticket = BertForSequenceClassification.from_pretrained(checkpoint_path)\n",
        "        optimizer = optim.Adam(ticket.parameters(), lr=learning_rate)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Define and initialize training arguments\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=\"./results\",\n",
        "            num_train_epochs=3,\n",
        "            per_device_train_batch_size=batch_size,\n",
        "            per_device_eval_batch_size=batch_size,\n",
        "            learning_rate=learning_rate,\n",
        "            weight_decay=0.01,\n",
        "            logging_dir='./logs',\n",
        "            evaluation_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"eval_f1_score\",  # Update metric name to eval_f1_score\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=ticket,\n",
        "            args=training_args,\n",
        "            train_dataset=tokenized_datasets[\"train\"],\n",
        "            eval_dataset=tokenized_datasets[\"validation\"],\n",
        "            data_collator=data_collator,\n",
        "            tokenizer=tokenizer,\n",
        "            compute_metrics=compute_metrics,\n",
        "        )\n",
        "        trainer.train()\n",
        "        predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
        "        if f1_score(predictions.label_ids, predictions.predictions.argmax(-1)) > convergence_threshold:\n",
        "            ensemble_set.append(ticket)\n",
        "\n",
        "            # Log hyperparameters and metrics to wandb\n",
        "            wandb.log({\"iteration\": iteration, \"f1_score\": f1_score(predictions.label_ids, predictions.predictions.argmax(-1))})\n",
        "\n",
        "    return ensemble_set\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set up wandb configuration\n",
        "    wandb_config = {\n",
        "        \"num_iterations\": 5,\n",
        "        \"learning_rate\": 2e-5,\n",
        "        \"batch_size\": 16,\n",
        "        \"convergence_threshold\": 0.001,\n",
        "    }\n",
        "    wandb.config.update(wandb_config)\n",
        "\n",
        "    ensemble_set = ensemble_bert(\n",
        "        num_iterations=wandb_config[\"num_iterations\"],\n",
        "        learning_rate=wandb_config[\"learning_rate\"],\n",
        "        batch_size=wandb_config[\"batch_size\"],\n",
        "        convergence_threshold=wandb_config[\"convergence_threshold\"],\n",
        "    )\n",
        "\n",
        "    f1_scores = []\n",
        "    for iteration, model in enumerate(ensemble_set):\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=tokenized_datasets[\"train\"],\n",
        "            eval_dataset=tokenized_datasets[\"validation\"],\n",
        "            data_collator=data_collator,\n",
        "            tokenizer=tokenizer,\n",
        "            compute_metrics=compute_metrics,\n",
        "        )\n",
        "        trainer.train()\n",
        "        predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
        "        f1 = f1_score(predictions.label_ids, predictions.predictions.argmax(-1))\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        # Log F1 score for each ensemble iteration to wandb\n",
        "        wandb.log({\"ensemble_iteration\": iteration, \"f1_score\": f1})\n",
        "\n",
        "    # Save the ensemble_set\n",
        "    os.makedirs(\"ensemble_models\", exist_ok=True)\n",
        "    for i, model in enumerate(ensemble_set):\n",
        "        model.save_pretrained(f\"ensemble_models/model_{i}\")\n",
        "\n",
        "    # Save the best model to the Hugging Face Hub\n",
        "    best_model_index = f1_scores.index(max(f1_scores))\n",
        "    best_model = ensemble_set[best_model_index]\n",
        "    model_name = \"your_hub_username/your_model_name\"\n",
        "    best_model.save_pretrained(model_name)\n",
        "    tokenizer.save_pretrained(model_name)\n",
        "    wandb.save(f\"ensemble_models/model_{best_model_index}/config.json\")\n",
        "\n",
        "    # Plotting Accuracy vs. Ensemble Iteration\n",
        "    plt.plot(range(len(f1_scores)), f1_scores)\n",
        "    plt.title(\"F1 score vs. Ensemble Iteration\")\n",
        "    plt.xlabel(\"Ensemble Iteration\")\n",
        "    plt.ylabel(\"F1 score\")\n",
        "    plt.show()\n",
        "\n",
        "    # Finish wandb run\n",
        "    wandb.finish()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+5oxOplXi7NGgis+u7Egk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "37feb8efbec74945bfc80a51f26e3b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9328f0ed981a47d6bba51206ef937ef3",
              "IPY_MODEL_a26dbf294145428fa9ade6d8820ab8ec",
              "IPY_MODEL_fb920cdaac3c4edd8cd096c6cabdf999"
            ],
            "layout": "IPY_MODEL_eb63c2c8ba344a8cac8bc02fe29a9675"
          }
        },
        "9328f0ed981a47d6bba51206ef937ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5a21f30f43048dab34ead077bef8a36",
            "placeholder": "",
            "style": "IPY_MODEL_6cc07f578836409b85027b22c56aa8c4",
            "value": "Map:100%"
          }
        },
        "a26dbf294145428fa9ade6d8820ab8ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_944151739a1a4541b132b5834bcbc8ad",
            "max": 1043,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2000dd9c37894e37aacb3c5d37144d36",
            "value": 1043
          }
        },
        "fb920cdaac3c4edd8cd096c6cabdf999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80f66a1c13e64f70907dfc423f687732",
            "placeholder": "",
            "style": "IPY_MODEL_5ab541a7523d484db2b0cd44fd8a5b26",
            "value": "1043/1043[00:00&lt;00:00,3696.16examples/s]"
          }
        },
        "eb63c2c8ba344a8cac8bc02fe29a9675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5a21f30f43048dab34ead077bef8a36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cc07f578836409b85027b22c56aa8c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "944151739a1a4541b132b5834bcbc8ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2000dd9c37894e37aacb3c5d37144d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80f66a1c13e64f70907dfc423f687732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ab541a7523d484db2b0cd44fd8a5b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}